{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Notebook shows the code used to run LIME detections on images using YOLOv3 with a Darknet-53 backbone. Code used was from https://github.com/AntMorais/yolime."
      ],
      "metadata": {
        "id": "oeYZbabojaPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to google drive and setup path"
      ],
      "metadata": {
        "id": "PAF6zvl7mtGw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx4vpo8O0guE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-WjHljk0q4h"
      },
      "outputs": [],
      "source": [
        "path_setup = '/content/drive/MyDrive/'\n",
        "img_folder = path_setup+\"lime/LIME_images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEFlI-Mi0q0P"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/lime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone repository to google drive"
      ],
      "metadata": {
        "id": "BRIw82ZIiMq0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUVVd1L_0qt2"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AntMorais/yolime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install and setup LIME"
      ],
      "metadata": {
        "id": "EMT0vbcxiQsF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhnwZcO10qh-"
      },
      "outputs": [],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvlfh2f31S8e",
        "outputId": "075f4dca-af22-4b21-82d4-b8116ccafe3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/lime/yolime\n",
            "rm -rf ./obj/image_opencv.o ./obj/http_stream.o ./obj/gemm.o ./obj/utils.o ./obj/dark_cuda.o ./obj/convolutional_layer.o ./obj/list.o ./obj/image.o ./obj/activations.o ./obj/im2col.o ./obj/col2im.o ./obj/blas.o ./obj/crop_layer.o ./obj/dropout_layer.o ./obj/maxpool_layer.o ./obj/softmax_layer.o ./obj/data.o ./obj/matrix.o ./obj/network.o ./obj/connected_layer.o ./obj/cost_layer.o ./obj/parser.o ./obj/option_list.o ./obj/darknet.o ./obj/detection_layer.o ./obj/captcha.o ./obj/route_layer.o ./obj/writing.o ./obj/box.o ./obj/nightmare.o ./obj/normalization_layer.o ./obj/avgpool_layer.o ./obj/coco.o ./obj/dice.o ./obj/yolo.o ./obj/detector.o ./obj/layer.o ./obj/compare.o ./obj/classifier.o ./obj/local_layer.o ./obj/swag.o ./obj/shortcut_layer.o ./obj/activation_layer.o ./obj/rnn_layer.o ./obj/gru_layer.o ./obj/rnn.o ./obj/rnn_vid.o ./obj/crnn_layer.o ./obj/demo.o ./obj/tag.o ./obj/cifar.o ./obj/go.o ./obj/batchnorm_layer.o ./obj/art.o ./obj/region_layer.o ./obj/reorg_layer.o ./obj/reorg_old_layer.o ./obj/super.o ./obj/voxel.o ./obj/tree.o ./obj/yolo_layer.o ./obj/gaussian_yolo_layer.o ./obj/upsample_layer.o ./obj/lstm_layer.o ./obj/conv_lstm_layer.o ./obj/scale_channels_layer.o ./obj/sam_layer.o ./obj/convolutional_kernels.o ./obj/activation_kernels.o ./obj/im2col_kernels.o ./obj/col2im_kernels.o ./obj/blas_kernels.o ./obj/crop_layer_kernels.o ./obj/dropout_layer_kernels.o ./obj/maxpool_layer_kernels.o ./obj/network_kernels.o ./obj/avgpool_layer_kernels.o darknet libdarknet.so uselib\n"
          ]
        }
      ],
      "source": [
        "%cd yolime\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Images and Model Weights"
      ],
      "metadata": {
        "id": "YJ7ATnEljEBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAy7cGL7GWI1"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import darknet\n",
        "import darknet_images\n",
        "\n",
        "\n",
        "# No caso de querermos correr a rede default (para testar por ex.)\n",
        "#txt_input = path_setup + \"FIRELOC_DATA/train.txt\"\n",
        "#weights = path_setup + \"FIRELOC_DATA/yolov4.weights\"\n",
        "#config_file = \"cfg/yolov4.cfg\"\n",
        "#data_file = \"cfg/coco.data\"\n",
        "\n",
        "# No caso de querermos a rede FireLoc\n",
        "txt_input = \"data/train.txt\"\n",
        "weights = path_setup + \"/yolov3/darknet/backup/yolov3_custom_final.weights\"\n",
        "\n",
        "path_setup = \"/content/drive/MyDrive/\"\n",
        "path_cfg = \"/content/drive/MyDrive/yolov3/darknet/cfg/\"\n",
        "config_file = \"cfg/yolov3_custom.cfg\"\n",
        "data_file = \"data/obj.data\"\n",
        "# outras configurações\n",
        "batch_size = True\n",
        "dont_show = True\n",
        "ext_output = True\n",
        "save_labels = True\n",
        "thresh = 0.3\n",
        "\n",
        "# number of samples generated in explain_instance\n",
        "num_samples = 20000\n",
        "# max number of features to be used in the explanation (default is 100000)\n",
        "num_features = 1000000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose which image to run LIME on"
      ],
      "metadata": {
        "id": "j_Ne1Ylpi_3J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65UuvjiRpRqe"
      },
      "outputs": [],
      "source": [
        "images = darknet_images.load_images(txt_input)\n",
        "image_name = images[0]\n",
        "folder_name = image_name.replace(\"data/obj/\",\"\").replace(\".jpg\",\"\")\n",
        "#!mkdir img_foler/folder_name\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run all cells from here for each image"
      ],
      "metadata": {
        "id": "1HWPVXf5jKBF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpEqLCTNVHSf"
      },
      "outputs": [],
      "source": [
        "network, class_names, class_colors = darknet.load_network(\n",
        "        config_file,\n",
        "        data_file,\n",
        "        weights,\n",
        "        batch_size\n",
        ")\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------------------------------\n",
        "\n",
        "width = darknet.network_width(network)\n",
        "height = darknet.network_height(network)\n",
        "image = cv2.imread(image_name)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_resized = cv2.resize(image_rgb, (width, height),\n",
        "                            interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "\n",
        "\n",
        "def grey_out(image, x, y, w, h):\n",
        "    # input: ndarray returned by imread, height and width\n",
        "    #Create an array of object rect which represents the region of interest\n",
        "    rect = [[x-w/2,y+h/2], [x-w/2,y-h/2], [x+w/2,y-h/2],[x+w/2,y+h/2]]\n",
        "    mask = np.array([rect], dtype=np.int32)\n",
        "\n",
        "    #Create a new array filled with zeros, size equal to size of the image to be filtered\n",
        "    image2 = np.zeros((width, height), np.int8)\n",
        "\n",
        "    cv2.fillPoly(image2, [mask],255)    \n",
        "    maskimage2 = cv2.inRange(image2, 1, 255)\n",
        "    out = cv2.bitwise_and(image, image, mask=maskimage2)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "def lime_classification_function(image_numpy):\n",
        "\n",
        "    probabilities = np.zeros((len(image_numpy), len(class_names)))\n",
        "    for i in range(len(image_numpy)):\n",
        "        img = image_numpy[i]\n",
        "        image, detections = darknet_images.image_detection_lime(\n",
        "                img, network, class_names,\n",
        "                class_colors, thresh\n",
        "                )\n",
        "\n",
        "        if save_labels:\n",
        "            darknet_images.save_annotations(image_name, image, detections, class_names)\n",
        "        if not dont_show:\n",
        "            cv2.imshow('Inference', image)\n",
        "            if cv2.waitKey() & 0xFF == ord('q'):\n",
        "                return\n",
        "        with open(\"probabilityArray.txt\",\"r\") as prob_array:\n",
        "            lines = [float(line.rstrip()) for line in prob_array]\n",
        "            probabilities[i] = lines\n",
        "    return probabilities\n",
        "\n",
        "\n",
        "# input:\n",
        "# - class_name: string with name of class we want to explain (e.g. \"Dog\", \"Smoke\" ...)\n",
        "# output:\n",
        "# - picked_class: index for the bounding box with most confidence of the specified input class \n",
        "# - detections\n",
        "def get_most_confident_bbox(class_name):\n",
        "\n",
        "    image_original, detections = darknet_images.image_detection(\n",
        "                image_name, network, class_names,\n",
        "                class_colors, thresh\n",
        "                )\n",
        "    darknet.print_detections(detections, ext_output)\n",
        "    #detections is a list of tuples (class, confidence,(coordinates))\n",
        "    picked_class = -1\n",
        "    print(detections)\n",
        "    for i in range(len(detections)):\n",
        "        _tuple = detections[i]\n",
        "        if _tuple[0] == class_name:\n",
        "            coordinates = _tuple[2]\n",
        "            with open(\"coordinates.txt\",\"w\") as coord_file:\n",
        "                # we convert the coordinates to relative because that is how it is used in the C files\n",
        "                coordinates_rel = darknet_images.convert2relative(image_original,coordinates)\n",
        "                for _coord in coordinates_rel:\n",
        "                    coord_file.write(str(_coord)+\"\\n\")\n",
        "                picked_class = i\n",
        "            break\n",
        "    if picked_class == -1:\n",
        "        print(\"There is no \" + class_name + \" in this image!\")\n",
        "    return picked_class, detections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATNq8CcdIi9M"
      },
      "outputs": [],
      "source": [
        "class_name = 'polyp'\n",
        "picked_class, coordinates = get_most_confident_bbox(class_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS--SzzeIsa9"
      },
      "outputs": [],
      "source": [
        "# pass the image, the height and width\n",
        "greyed_out_image = grey_out(image_resized, coordinates[picked_class][2][0], coordinates[picked_class][2][1],\\\n",
        "                            coordinates[picked_class][2][2], coordinates[picked_class][2][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1RIdm9TItwD"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yppk_gMEy44S"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(cv2.cvtColor(greyed_out_image, cv2.COLOR_BGR2RGB))\n",
        "cv2.imwrite(img_folder+folder_name+\"/cropped.png\",cv2.cvtColor(greyed_out_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRk9z-5dzX4x"
      },
      "outputs": [],
      "source": [
        "predictions_jpg = cv2.imread(\"predictions.jpg\")\n",
        "frame_normed = 255 * (frame - frame.min()) / (frame.max() - frame.min())\n",
        "frame_normed = np.array(frame_normed, np.int)\n",
        "cv2.imwrite(img_folder+ folder_name + \"/predictions.jpg\", predictions_jpg)\n",
        "cv2_imshow(predictions_jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "01975dd72b0b4d6abc203f407ce3c0e2",
            "7da94a3d32a84931a2b6c65e8648612a",
            "4cbadcf5cdd24abc9c2c3b41719bbb28",
            "978adb933d7641fe9ad95719e2e1956c",
            "71954b4cce914d22b61ca010b5312197",
            "688c70f5ce3a4e3ea2099c687d2a2769",
            "7133003ee5e3475c85127ae76250e107",
            "a7785057e5214dc48bdb4d52b9267b13",
            "504793bc78174cd9aa76498c5aac13f7",
            "bb71b084c2464f3ea0f119a5682a2524",
            "75dbe90d89e54782a959c27ab9acf52a"
          ]
        },
        "id": "5hqebgyLIvhD",
        "outputId": "a83c52c5-52db-41dd-ddb4-f205fa079b7b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01975dd72b0b4d6abc203f407ce3c0e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from lime import lime_image\n",
        "#Objeto do tipo LimeImageExplainer\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "#Objeto do tipo ImageExplanation\n",
        "explanation = explainer.explain_instance(np.array(image_resized), \n",
        "                                         lime_classification_function, # classification function\n",
        "                                         top_labels=5, \n",
        "                                         hide_color=0, \n",
        "                                         num_samples=num_samples,\n",
        "                                         num_features=num_features) # number of images that will be sent to classification function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAltwvONcMka"
      },
      "outputs": [],
      "source": [
        "# mostra a imagem que acabámos de detetar\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBD1Hm4UcN03"
      },
      "outputs": [],
      "source": [
        "def show_bbox_centers(coordinates):\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    #mostrar centros das bounding boxes \n",
        "    xx = []\n",
        "    yy = []\n",
        "    for class_coord in coordinates:\n",
        "        xx.append(class_coord[2][0])\n",
        "        yy.append(class_coord[2][1])\n",
        "    plt.scatter(xx,\\\n",
        "            yy,\\\n",
        "            marker='o', color=\"red\")\n",
        "    \n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.segmentation import mark_boundaries\n",
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0],\\\n",
        "    positive_only=False, num_features=5\\\n",
        "    ,hide_rest=False)\n",
        "img_boundry2 = mark_boundaries(temp/255.0, mask)\n",
        "plt.imshow(img_boundry2)\n",
        "show_bbox_centers(coordinates)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAQFudTScPee"
      },
      "outputs": [],
      "source": [
        "def crop_img(img, new_filename, coordinates, picked_class):\n",
        "    [center_x, center_y, width, height] = [coord for coord in coordinates[picked_class][2]]\n",
        "    top_left_x = round(center_x - width/2)\n",
        "    top_left_y = round(center_y - height/2)\n",
        "    print(top_left_x)\n",
        "    print(top_left_y)\n",
        "    print(height)\n",
        "    print(width)\n",
        "    if top_left_x < 0:\n",
        "        top_left_x = 0\n",
        "    if top_left_y < 0:\n",
        "        top_left_y = 0\n",
        "    crop_img = img[top_left_y:top_left_y+round(height), top_left_x:top_left_x+round(width)]\n",
        "    plt.imshow(crop_img)\n",
        "    plt.show()\n",
        "    # guardo a nova imagem num ficheiro\n",
        "    cv2.imwrite(new_filename,crop_img)\n",
        "\n",
        "\n",
        "\n",
        "crop_img(img_boundry2, \"explanationHere.jpg\", coordinates, picked_class)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01975dd72b0b4d6abc203f407ce3c0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7da94a3d32a84931a2b6c65e8648612a",
              "IPY_MODEL_4cbadcf5cdd24abc9c2c3b41719bbb28",
              "IPY_MODEL_978adb933d7641fe9ad95719e2e1956c"
            ],
            "layout": "IPY_MODEL_71954b4cce914d22b61ca010b5312197"
          }
        },
        "4cbadcf5cdd24abc9c2c3b41719bbb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7785057e5214dc48bdb4d52b9267b13",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_504793bc78174cd9aa76498c5aac13f7",
            "value": 20000
          }
        },
        "504793bc78174cd9aa76498c5aac13f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "688c70f5ce3a4e3ea2099c687d2a2769": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7133003ee5e3475c85127ae76250e107": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71954b4cce914d22b61ca010b5312197": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75dbe90d89e54782a959c27ab9acf52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7da94a3d32a84931a2b6c65e8648612a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_688c70f5ce3a4e3ea2099c687d2a2769",
            "placeholder": "​",
            "style": "IPY_MODEL_7133003ee5e3475c85127ae76250e107",
            "value": "100%"
          }
        },
        "978adb933d7641fe9ad95719e2e1956c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb71b084c2464f3ea0f119a5682a2524",
            "placeholder": "​",
            "style": "IPY_MODEL_75dbe90d89e54782a959c27ab9acf52a",
            "value": " 20000/20000 [34:25&lt;00:00, 12.98it/s]"
          }
        },
        "a7785057e5214dc48bdb4d52b9267b13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb71b084c2464f3ea0f119a5682a2524": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}